# Python 程式設計入門
# 網路爬蟲 Web Crawler 基本篇
""" 
1.基本流程
2.抓取資料
3.解析資料
4.安裝套件
5.Cookie
6.追蹤網頁的連結
7.連續抓取頁面實務
"""
""" .................基本流程................ """
# 基本流程
""" 
1.連線到特定網址,抓取資料
2.解析資料,取得實際想要的部分
"""
 
""" .................抓取資料................ """
# 抓取資料
# 關鍵心法
""" 
盡可能的，讓程式模仿一個普通使用者的樣子
"""

""" .................解析資料................ """
# 解析資料

# JSON格式資料
""" 
使用內建的JSON模組即可
"""
# HTML格式資料
"""  
<html>
  <head>
    <title>HTML 格式文件</title>
  </head>
  <body>
    <div class="list:>
        <span>階層結構</span>
        <span>樹狀結構</span>
    </div>
  </body>
</html>

#使用第三方套件 BeautifulSoup來做解析
"""

""" .................安裝套件................ """
# 安裝套件
# PIP套件管理工具
""" 安裝Python時,就一起安裝了 """
#安裝BeautifulSoup
""" pip install beautifulsoup4 """

""" .................Cookie................ """
# Cookie
""" 網路存放在瀏覽器的一小段內容 """
#與伺服器的互動
""" 連線時 放在Request Headers 中送出 """

""" ..............追蹤網頁的連結............. """
# 追蹤網頁的連結

#Html的超連結
""" 
<html>
  <head>
    <title>HTML 格式文件</title>
  </head>
  <body>
    <a href="https://www.google.com/">Google</a> ＃Html的超連結
  </body>
</html> 
"""

""" ..............連續抓取頁面實務.............. """
#連續抓取頁面實務
"""  解析頁面的超連結，並結合程式邏輯完成 """